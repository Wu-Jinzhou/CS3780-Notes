\section{Perceptron}

\begin{itemize}
    \item \textbf{Theorem:} Given a dataset $S = \{(\vec{x}_1, y_1), \ldots, (\vec{x}_m, y_m)\}$ and a radius $R$ such that $\|\vec{x}_i\| \leq R$ for all $i \in [m]$. If $S$ is linearly separable with (geometric) \textbf{margin} $\gamma$, then Perceptron makes at most $R^2/\gamma^2$ updates before finding a consistent linear classifier.
    \item This upper bound holds even if
    \begin{itemize}
        \item We scale every instance in the training set
        \item We shuffle the training set
        \item We don't know the value of $\gamma$
    \end{itemize}
    \item Actual number of updates can vary, but we know it cannot be more than $R^2/\gamma^2$
\end{itemize}
